{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Rc_ahEnTF9m"
   },
   "source": [
    "# Predict tags on StackOverflow with linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5hmogPBTF9p"
   },
   "source": [
    "In this assignment you will learn how to predict tags for posts from [StackOverflow](https://stackoverflow.com). To solve this task you will use multilabel classification approach.\n",
    "\n",
    "### Libraries\n",
    "\n",
    "In this task you will need the following libraries:\n",
    "- [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    "- [Pandas](https://pandas.pydata.org) — a library providing high-performance, easy-to-use data structures and data analysis tools for the Python\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
    "- [NLTK](http://www.nltk.org) — a platform to work with natural language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSq4Uzh6TF9q"
   },
   "source": [
    "### Data\n",
    "\n",
    "You can find all data required for this assignment into the folder `/data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2V1gba1KTF9r"
   },
   "source": [
    "### Text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WnvsWcP9TF9t"
   },
   "source": [
    "For this assignment you will need to use a list of stop words. It can be downloaded from *nltk*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "R-RxVRvsTF9u",
    "outputId": "bb9bb432-14c0-4fb5-878c-e02bd816423e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bhanushree\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ErHWjimITF91"
   },
   "source": [
    "In this task you will deal with a dataset of post titles from StackOverflow. You are provided a split to 3 sets: *train*, *validation* and *test*. All corpora (except for *test*) contain titles of the posts and corresponding tags (100 tags are available). The *test* set doesn't contain answers. Upload the corpora using *pandas* and look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-ufeO-nfVGha"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDahiblaU-e7"
   },
   "source": [
    "Literal_eval package takes care of the preprocessing for the string so that it can be used in python. To know more on literal_eval please see the below documentation <br>\n",
    "https://kite.com/python/docs/ast.literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bubX7TSLVLXR"
   },
   "source": [
    "## Task 1: Create training, testing and validation data from the files given. Use title to be the independent variable and tags to be the dependent variable ( 5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBFMf3bhVPb_"
   },
   "source": [
    "Note: Ensure you apply literal_eval function on the tags column to ensure all the tags are readable in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x8iH7o77TF96"
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t')\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPaUfSVvTF99"
   },
   "outputs": [],
   "source": [
    "train = read_data('C:/Users/Bhanushree/Downloads/assignment july/Files_required_for_Stats_NLP_Project/train.tsv')\n",
    "validation = read_data('C:/Users/Bhanushree/Downloads/assignment july/Files_required_for_Stats_NLP_Project/validation.tsv')\n",
    "test = pd.read_csv('C:/Users/Bhanushree/Downloads/assignment july/Files_required_for_Stats_NLP_Project/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d4pPOmFvTF-B"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why odbc_exec always fail?</td>\n",
       "      <td>[php, sql]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Access a base classes variable from within a c...</td>\n",
       "      <td>[javascript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content-Type \"application/json\" not required i...</td>\n",
       "      <td>[ruby-on-rails, ruby]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sessions in Sinatra: Used to Pass Variable</td>\n",
       "      <td>[ruby, session]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting error - type \"json\" does not exist - i...</td>\n",
       "      <td>[ruby-on-rails, ruby, json]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                         Why odbc_exec always fail?   \n",
       "1  Access a base classes variable from within a c...   \n",
       "2  Content-Type \"application/json\" not required i...   \n",
       "3         Sessions in Sinatra: Used to Pass Variable   \n",
       "4  Getting error - type \"json\" does not exist - i...   \n",
       "\n",
       "                          tags  \n",
       "0                   [php, sql]  \n",
       "1                 [javascript]  \n",
       "2        [ruby-on-rails, ruby]  \n",
       "3              [ruby, session]  \n",
       "4  [ruby-on-rails, ruby, json]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USlubitlTF-G"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = train['title'].values, train['tags'].values\n",
    "X_val, y_val = validation['title'].values, validation['tags'].values\n",
    "X_test = test['title'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bcb3kXUSTF-M"
   },
   "source": [
    "## Task 2 (Pre-processing). Implement the function *text_prepare* following the instructions. After that, run the function *test_test_prepare* to test it on tiny cases. (10 points)\n",
    "\n",
    "One of the most known difficulties when working with natural data is that it's unstructured. For example, if you use it \"as is\" and extract tokens just by splitting the titles by whitespaces, you will see that there are many \"weird\" tokens like *3.5*, *?*,  *{}*, etc. To prevent the problems, it's usually useful to prepare the data in a custom way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PBSchmxtTF-N"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iI1plv6WTF-R"
   },
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE,\" \",text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE,\"\",text)\n",
    "    text = text.split();\n",
    "    return ' '.join([i for i in text if i not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5LQEgMATF-Y"
   },
   "outputs": [],
   "source": [
    "def test_text_prepare():\n",
    "    examples = [\"SQL Server - any equivalent of Excel's CHOOSE function?\",\n",
    "                \"How to free c++ memory vector<int> * arr?\"]\n",
    "    answers = [\"sql server equivalent excels choose function\", \n",
    "               \"free c++ memory vectorint arr\"]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if text_prepare(ex) != ans:\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t2DpralVokG"
   },
   "source": [
    "Execute the test_text_prepare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [text_prepare(x) for x in X_train]\n",
    "X_val = [text_prepare(x) for x in X_val]\n",
    "X_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ettHAZ8eVt1R"
   },
   "source": [
    "*Note: You should pass the above test to ensure the text preprocessing is done before our analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV5JC6HXTF-k"
   },
   "source": [
    "Now we can preprocess the titles using function *text_prepare* and  making sure that the headers don't have bad symbols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOZKuHnGTF-k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['draw stacked dotplot r',\n",
       " 'mysql select records datetime field less specified value',\n",
       " 'terminate windows phone 81 app',\n",
       " 'get current time specific country via jquery',\n",
       " 'configuring tomcat use ssl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AfWls32MV5Uu"
   },
   "source": [
    "Print the top 5 elements in x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BP3LiGsTF-o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At_ZTeqTTF-t"
   },
   "source": [
    "## Task 2 (WordsTagsCount) - Find 3 most popular tags and 3 most popular words in the train data. - 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2mT1f7gWKSu"
   },
   "source": [
    "Note: The words which appear the most are considered as popular in this case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-eQoxipTF-v"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Dictionary of all tags from train corpus with their counts.\n",
    "tags_counts =  defaultdict(int)\n",
    "# Dictionary of all words from train corpus with their counts.\n",
    "words_counts =  defaultdict(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xkwg8_WNTF-3"
   },
   "source": [
    "We are assuming that *tags_counts* and *words_counts* are dictionaries like `{'some_word_or_tag': frequency}`. After applying the sorting procedure, results will be look like this: `[('most_popular_word_or_tag', frequency), ('less_popular_word_or_tag', frequency), ...]`.\n",
    "\n",
    "eg: \n",
    "Tag 1 - 100 Tag 2 - 65 Tag 3 - 250 <br>\n",
    "after sorting looks like, <br>\n",
    "Tag 3 - 250 Tag 1 - 100 Tag 2 - 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RSCPa54uTF-4"
   },
   "outputs": [],
   "source": [
    "for text in X_train:\n",
    "    for word in text.split():\n",
    "        words_counts[word] += 1\n",
    "\n",
    "\n",
    "for tags in y_train:\n",
    "    for tag in tags:\n",
    "        tags_counts[tag] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xk7M4uJ_TF-8"
   },
   "source": [
    "## Task - 3 Transforming text to a vector (10 points)\n",
    "\n",
    "Machine Learning algorithms work with numeric data and we cannot use the provided text data \"as is\". There are many ways to transform text data to numeric vectors. In this task you will try to use two of them.\n",
    "\n",
    "#### Bag of words\n",
    "\n",
    "One of the well-known approaches is a *bag-of-words* representation. To create this transformation, follow the steps:\n",
    "1. Find *N* most popular words in train corpus and numerate them. Now we have a dictionary of the most popular words.\n",
    "2. For each title in the corpora create a zero vector with the dimension equals to *N*.\n",
    "3. For each text in the corpora iterate over words which are in the dictionary and increase by 1 the corresponding coordinate.\n",
    "\n",
    "Let's try to do it for a toy example. Imagine that we have *N* = 4 and the list of the most popular words is \n",
    "\n",
    "    ['hi', 'you', 'me', 'are']\n",
    "\n",
    "Then we need to numerate them, for example, like this: \n",
    "\n",
    "    {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "\n",
    "And we have the text, which we want to transform to the vector:\n",
    "\n",
    "    'hi how are you'\n",
    "\n",
    "For this text we create a corresponding zero vector \n",
    "\n",
    "    [0, 0, 0, 0]\n",
    "    \n",
    "And iterate over all words, and if the word is in the dictionary, we increase the value of the corresponding position in the vector:\n",
    "\n",
    "    'hi':  [1, 0, 0, 0]\n",
    "    'how': [1, 0, 0, 0] # word 'how' is not in our dictionary\n",
    "    'are': [1, 0, 0, 1]\n",
    "    'you': [1, 1, 0, 1]\n",
    "\n",
    "The resulting vector will be \n",
    "\n",
    "    [1, 1, 0, 1]\n",
    "   \n",
    "Implement the described encoding in the function *my_bag_of_words* with the size of the dictionary equals to 5000. To find the most common words use train data. You can test your code using the function *test_my_bag_of_words*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ER1oq48TF-9"
   },
   "outputs": [],
   "source": [
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:6000]\n",
    "DICT_SIZE = 5000\n",
    "WORDS_TO_INDEX = {p[0]:i for i,p in enumerate(most_common_words[:DICT_SIZE])} ####### YOUR CODE HERE #######\n",
    "INDEX_TO_WORDS = {WORDS_TO_INDEX[k]:k for k in WORDS_TO_INDEX}####### YOUR CODE HERE #######\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        dict_size: size of the dictionary\n",
    "        \n",
    "        return a vector which is a bag-of-words representation of 'text'\n",
    "    \"\"\"\n",
    "    \n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split():\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] += 1\n",
    "    \n",
    "    return result_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnLYWnsaTF_A"
   },
   "outputs": [],
   "source": [
    "def test_my_bag_of_words():\n",
    "    words_to_index = {'hi': 0, 'you': 1, 'me': 2, 'are': 3}\n",
    "    examples = ['hi how are you']\n",
    "    answers = [[1, 1, 0, 1]]\n",
    "    for ex, ans in zip(examples, answers):\n",
    "        if (my_bag_of_words(ex, words_to_index, 4) != ans).any():\n",
    "            return \"Wrong answer for the case: '%s'\" % ex\n",
    "    return 'Basic tests are passed.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOlSiUqEW3jD"
   },
   "source": [
    "Execute the test_text_prepare function <br>\n",
    "*<u>Note:</u> You should pass the above test to ensure BOW is working correctly!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXW3ALCITF_H"
   },
   "source": [
    "Now apply the implemented function to all samples (this might take up to a minute):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m39xHB2yTF_H"
   },
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DZwPWB1TF_K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (100000, 5000)\n",
      "X_val shape  (30000, 5000)\n",
      "X_test shape  (20000, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPXTUeNSTF_N"
   },
   "source": [
    "As you might notice, we transform the data to sparse representation, to store the useful information efficiently. There are many types: of such representations, however sklearn algorithms can work only with  csr matrix, so we will use this one.<br>\n",
    "<u>Documentations on sparse matrix:</u> <br>\n",
    "(https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) \n",
    "(https://docs.scipy.org/doc/scipy/reference/sparse.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i8AMzsVxTF_Q"
   },
   "source": [
    "\n",
    "For the 11th row in *X_train_mybag* find how many non-zero elements it has. In this task the answer (variable *non_zero_elements_count*) should be a number, e.g. 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYAFKGfKTF_V"
   },
   "source": [
    "## Task 4 - TF-IDF (5 points)\n",
    "\n",
    "The second approach extends the bag-of-words framework by taking into account total frequencies of words in the corpora. It helps to penalize too frequent words and provide better features space. \n",
    "\n",
    "Implement function *tfidf_features* using class  from *scikit-learn*. Use *train* corpus to train a vectorizer. Don't forget to take a look into the arguments that you can pass to it. We suggest that you filter out too rare words (occur less than in 5 titles) and too frequent words (occur more than in 90% of the titles). Also, use bigrams along with unigrams in your vocabulary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1s3uEKmjYpuh"
   },
   "source": [
    "## Write a function which takes x_train, x_val and x_test as input and return the tf-idf features of the same and the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkz1RYsBTF_Z"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6V7FPirTF_i"
   },
   "outputs": [],
   "source": [
    "def tfidf_features(X_train, X_val, X_test):\n",
    "    \"\"\"\n",
    "        X_train, X_val, X_test — samples        \n",
    "        return TF-IDF vectorized representation of each sample and vocabulary\n",
    "    \"\"\"\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.9, ngram_range=(1, 2),\n",
    "                                       token_pattern='(\\S+)')  \n",
    "    X_train=tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_val=tfidf_vectorizer.transform(X_val)\n",
    "    X_test=tfidf_vectorizer.transform(X_test)\n",
    "                                       \n",
    "    return X_train, X_val, X_test, tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySnV2zCBTF_p"
   },
   "outputs": [],
   "source": [
    "X_train_tfidf, X_val_tfidf, X_test_tfidf, tfidf_vocab = tfidf_features(X_train, X_val, X_test)\n",
    "tfidf_reversed_vocab = {i:word for word,i in tfidf_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_aopTTNL5G1"
   },
   "source": [
    "Print the index of string \"C#\" in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-3wqTTMCRi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1976"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vocab['c++']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYYO2kdiTF_6"
   },
   "source": [
    "## Task 5: Classification (15 points)\n",
    "MultiLabel classifier\n",
    "\n",
    "As we have noticed before, in this task each example can have multiple tags. To deal with such kind of prediction, we need to transform labels in a binary form and the prediction will be a mask of 0s and 1s. For this purpose it is convenient to use MultiLabelBinarizer from sklearn. <br>\n",
    "<u>Documentation:</u> <br>\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojeCe_e_TF_7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p8JYQr8YTF_-"
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer(classes=sorted(tags_counts.keys()))\n",
    "y_train = mlb.fit_transform(y_train)\n",
    "y_val = mlb.fit_transform(y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qN1NUA3DTGAB"
   },
   "source": [
    "In this task we suggest to use One-vs-Rest approach, which is implemented in [OneVsRestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) class. In this approach *k* classifiers (= number of tags) are trained. As a basic classifier, use [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). It is one of the simplest methods, but often it performs good enough in text classification tasks. It might take some time, because a number of classifiers to train is large.\n",
    "\n",
    "**OneVsRest multi-label strategy**\n",
    "\n",
    "The Multi-label algorithm accepts a binary mask over multiple labels. The result for each prediction will be an array of 0s and 1s marking which class labels apply to each row input sample.\n",
    "\n",
    "**Logistic Regression & SVM**\n",
    "\n",
    "OneVsRest strategy can be used for multi-label learning, where a classifier is used to predict multiple labels for instance. LR & SVM supports multi-class, but we are in a multi-label scenario, therefore, we wrap classifiers in the OneVsRestClassifier.\n",
    "\n",
    "*If you want to learn more about OneVsRest, check out these links:*\n",
    "- *https://towardsdatascience.com/multi-label-text-classification-with-scikit-learn-30714b7819c5*\n",
    "- *https://towardsdatascience.com/journey-to-the-center-of-multi-label-classification-384c40229bff*\n",
    "- *https://medium.com/coinmonks/multi-label-classification-blog-tags-prediction-using-nlp-b0b5ee6686fc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Pj6MDkbTGAC"
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition.nmf import NMF\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUHZR2TWTGAF"
   },
   "outputs": [],
   "source": [
    "def train_classifier(X_train, y_train):\n",
    "    \n",
    "    model = OneVsRestClassifier(LogisticRegression(random_state=0)).fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k660NfRFTGAL"
   },
   "source": [
    "Train the classifiers for different data transformations: *bag-of-words* and *tf-idf*.\n",
    "classifier_mybag = model for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXyhN-yDTGAP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanushree\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Bhanushree\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier_mybag = train_classifier(X_train_mybag, y_train)\n",
    "classifier_tfidf = train_classifier(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijQZCd9cTGAU"
   },
   "source": [
    "Now you can create predictions for the data. You will need two types of predictions: labels and scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0QT7uWddTGAV"
   },
   "outputs": [],
   "source": [
    "y_val_predicted_labels_mybag = classifier_mybag.predict(X_val_mybag)\n",
    "y_val_predicted_scores_mybag = classifier_mybag.decision_function(X_val_mybag)\n",
    "\n",
    "y_val_predicted_labels_tfidf = classifier_tfidf.predict(X_val_tfidf)\n",
    "y_val_predicted_scores_tfidf = classifier_tfidf.decision_function(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\todbc_exec always fail\n",
      "True labels:\tphp,sql\n",
      "Predicted labels:\t\n",
      "\n",
      "\n",
      "Title:\taccess base classes variable within child class\n",
      "True labels:\tjavascript\n",
      "Predicted labels:\t\n",
      "\n",
      "\n",
      "Title:\tcontenttype application json required rails\n",
      "True labels:\truby,ruby-on-rails\n",
      "Predicted labels:\tjson,ruby-on-rails\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_pred_inversed = mlb.inverse_transform(y_val_predicted_labels_tfidf)\n",
    "y_val_inversed = mlb.inverse_transform(y_val)\n",
    "for i in range(3):\n",
    "    print('Title:\\t{}\\nTrue labels:\\t{}\\nPredicted labels:\\t{}\\n\\n'.format(\n",
    "        X_val[i],\n",
    "        ','.join(y_val_inversed[i]),\n",
    "        ','.join(y_val_pred_inversed[i])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9n0TEtHTGAj"
   },
   "source": [
    "Now, we would need to compare the results of different predictions, e.g. to see whether TF-IDF transformation helps or to try different regularization techniques in logistic regression. For all these experiments, we need to setup evaluation procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVqAxDxqTGAk"
   },
   "source": [
    "## Evaluation (10 points)\n",
    "\n",
    "To evaluate the results we will use several classification metrics:\n",
    " - [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    " - [F1-score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)\n",
    " - [Area under ROC-curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    " - [Area under precision-recall curve](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score) \n",
    " \n",
    "Make sure you are familiar with all of them. If you want a refresher, you can click the link to their documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YmNhVsU9K9-"
   },
   "source": [
    "## Import the necessary libraries for the above metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBvrkOUYTGAl"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNkYBl_wTGAp"
   },
   "source": [
    "Define the function *print_evaluation_scores* which takes y_val and predicted as input calculates and prints the following output:\n",
    " - *accuracy*\n",
    " - *F1-score - Average = 'weighted'* \n",
    " - *Precision - Average = 'macro'*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4nevWnhTGAq"
   },
   "outputs": [],
   "source": [
    "def print_evaluation_scores(y_val, predicted):\n",
    "    accuracy=accuracy_score(y_val, predicted)\n",
    "    f1_score_macro=f1_score(y_val, predicted, average='macro')\n",
    "    f1_score_micro=f1_score(y_val, predicted, average='micro')\n",
    "    f1_score_weighted=f1_score(y_val, predicted, average='weighted')\n",
    "    precision_macro=average_precision_score(y_val, predicted, average='macro')\n",
    "    precision_micro=average_precision_score(y_val, predicted, average='micro')\n",
    "    precision_weighted=average_precision_score(y_val, predicted, average='weighted')\n",
    "    print(accuracy,f1_score_macro,f1_score_micro,f1_score_weighted,precision_macro,precision_micro,precision_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G92GIO4dTGAt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words\n",
      "0.358 0.5047325582597497 0.6710820449370445 0.6486950381244107 0.34458812912520126 0.4812849070834009 0.5108520393587743\n",
      "Tfidf\n",
      "0.3339666666666667 0.44571798903055987 0.641831238779174 0.614374123945813 0.30203873557248717 0.45700499415140816 0.48511300507698935\n"
     ]
    }
   ],
   "source": [
    "print('Bag-of-words')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_mybag)\n",
    "print('Tfidf')\n",
    "print_evaluation_scores(y_val, y_val_predicted_labels_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kT7oso8ZTGAv"
   },
   "source": [
    "You might also want to plot some form of the [ROC curve](http://scikit-learn.org/stable/modules/model_evaluation.html#receiver-operating-characteristic-roc) for the case of multi-label classification. The input parameters for the roc curve are:\n",
    " - true labels\n",
    " - decision functions scores\n",
    " - number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4hbW3SeBVxz"
   },
   "source": [
    "Import the roc_auc function from the metrics.py file provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_9M0AI4TGAv"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(tags_counts)\n",
    "roc_auc(y_val, y_val_predicted_scores_mybag, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwNpUEVLTGA2"
   },
   "outputs": [],
   "source": [
    "n_classes = len(tags_counts)\n",
    "roc_auc_score(y_val, y_val_predicted_scores_tfidf, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9S3Ddz7LTGA3"
   },
   "source": [
    "## Task 4 (MultilabelClassification) - Optional \n",
    "** Once we have the evaluation set up, we suggest that you experiment a bit with training your classifiers. We will use *F1-score weighted* as an evaluation metric. Our recommendation:\n",
    "- compare the quality of the bag-of-words and TF-IDF approaches and chose one of them.\n",
    "- for the chosen one, try *L1* and *L2*-regularization techniques in Logistic Regression with different coefficients (e.g. C equal to 0.1, 1, 10, 100).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ers40KuOTGA4"
   },
   "outputs": [],
   "source": [
    "def print_words_for_tag(classifier, tag, tags_classes, index_to_words, all_words):\n",
    "    \"\"\"\n",
    "        classifier: trained classifier\n",
    "        tag: particular tag\n",
    "        tags_classes: a list of classes names from MultiLabelBinarizer\n",
    "        index_to_words: index_to_words transformation\n",
    "        all_words: all words in the dictionary\n",
    "        \n",
    "        return nothing, just print top 5 positive and top 5 negative words for current tag\n",
    "    \"\"\"\n",
    "    print('Tag:\\t{}'.format(tag))\n",
    "    est = classifier.estimators_[tags_classes.index(tag)]\n",
    "    top_positive_words = [index_to_words[index] for index in est.coef_.argsort().tolist()[0][-5:]]  # top-5 words sorted by the coefficiens.\n",
    "    top_negative_words = [index_to_words[index] for index in est.coef_.argsort().tolist()[0][:5]] # bottom-5 words  sorted by the coefficients.\n",
    "    print('Top positive words:\\t{}'.format(', '.join(top_positive_words)))\n",
    "    print('Top negative words:\\t{}\\n'.format(', '.join(top_negative_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mdqTO269TGA8"
   },
   "source": [
    "When you are happy with the quality, create predictions for *test* set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M51F10f9TGBB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag:\tc\n",
      "Top positive words:\tgcc, printf, scanf, malloc, c\n",
      "Top negative words:\tjava, php, python, javascript, c#\n",
      "\n",
      "Tag:\tc++\n",
      "Top positive words:\topencv, mfc, boost, qt, c++\n",
      "Top negative words:\tjava, php, python, javascript, c#\n",
      "\n",
      "Tag:\tlinux\n",
      "Top positive words:\tsignal, address, c, ubuntu, linux\n",
      "Top negative words:\tjavascript, c#, jquery, array, method\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_words_for_tag(classifier_tfidf, 'c', mlb.classes, tfidf_reversed_vocab, ALL_WORDS)\n",
    "print_words_for_tag(classifier_tfidf, 'c++', mlb.classes, tfidf_reversed_vocab, ALL_WORDS)\n",
    "print_words_for_tag(classifier_tfidf, 'linux', mlb.classes, tfidf_reversed_vocab, ALL_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stats_NLP_Project_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
